{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import scipy.io\n",
    "from scipy import io\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat, matlab\n",
    "def load_mat(filename):\n",
    "    \"\"\"\n",
    "    This function should be called instead of direct scipy.io.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    \"\"\"\n",
    "\n",
    "    def _check_vars(d):\n",
    "        \"\"\"\n",
    "        Checks if entries in dictionary are mat-objects. If yes\n",
    "        todict is called to change them to nested dictionaries\n",
    "        \"\"\"\n",
    "        for key in d:\n",
    "            if isinstance(d[key], matlab.mio5_params.mat_struct):\n",
    "                d[key] = _todict(d[key])\n",
    "            elif isinstance(d[key], np.ndarray):\n",
    "                d[key] = _toarray(d[key])\n",
    "        return d\n",
    "\n",
    "    def _todict(matobj):\n",
    "        \"\"\"\n",
    "        A recursive function which constructs from matobjects nested dictionaries\n",
    "        \"\"\"\n",
    "        d = {}\n",
    "        for strg in matobj._fieldnames:\n",
    "            elem = matobj.__dict__[strg]\n",
    "            if isinstance(elem, matlab.mio5_params.mat_struct):\n",
    "                d[strg] = _todict(elem)\n",
    "            elif isinstance(elem, np.ndarray):\n",
    "                d[strg] = _toarray(elem)\n",
    "            else:\n",
    "                d[strg] = elem\n",
    "        return d\n",
    "\n",
    "    def _toarray(ndarray):\n",
    "        \"\"\"\n",
    "        A recursive function which constructs ndarray from cellarrays\n",
    "        (which are loaded as numpy ndarrays), recursing into the elements\n",
    "        if they contain matobjects.\n",
    "        \"\"\"\n",
    "        if ndarray.dtype != 'float64':\n",
    "            elem_list = []\n",
    "            for sub_elem in ndarray:\n",
    "                if isinstance(sub_elem, matlab.mio5_params.mat_struct):\n",
    "                    elem_list.append(_todict(sub_elem))\n",
    "                elif isinstance(sub_elem, np.ndarray):\n",
    "                    elem_list.append(_toarray(sub_elem))\n",
    "                else:\n",
    "                    elem_list.append(sub_elem)\n",
    "            return np.array(elem_list)\n",
    "        else:\n",
    "            return ndarray\n",
    "\n",
    "    data = loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_vars(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = curr_file['trial_results'][0][1]['RT1']\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrial = 300\n",
    "nCatch = 5\n",
    "nTotal = nTrial + nCatch\n",
    "subList = glob.glob('S*.csv')\n",
    "subInfo = []\n",
    "subListMat = []\n",
    "# for i, sub in enumerate(subList):\n",
    "#     jfile = sub.replace('data.csv', 'subinfo.json')\n",
    "#     with open(jfile) as json_file:\n",
    "#         json_data = json.load(json_file)\n",
    "#     age = json_data[0][\"age\"]\n",
    "#     sex = json_data[0][\"sex\"]\n",
    "#     reward = json_data[0][\"reward\"]\n",
    "#     workerid = json_data[0][\"workerid\"]\n",
    "#     assignmentid = json_data[0][\"assignmentid\"]\n",
    "#     subInfo.append((sex,age, sub, reward))\n",
    "#     print((sex,age,sub,reward))\n",
    "#     print(workerid)\n",
    "#     print(assignmentid)\n",
    "#     subListMat.append(sub.replace('.csv', '.mat'))\n",
    "# subInfo\n",
    "# subListMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrial = 300\n",
    "nCatch = 5\n",
    "nTotal = nTrial + nCatch\n",
    "subList = glob.glob('S*.csv')\n",
    "i=0\n",
    "sub=subList[0]\n",
    "jfile = sub.replace('data.csv', 'subinfo.json')\n",
    "with open(jfile) as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "json_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model 1: baseline model with $\\alpha$, $\\beta$, $w$, and $\\gamma$\n",
    "\n",
    "|  | sub1 | sub2 | sub3 | sub4 | sub5 | sub6 | sub7 | sub8 |\n",
    "|-|-|-|-|-|-|-|-|-|\n",
    "| age | 38 | 22 | 27 | 48 | 34 | 66 | 29 | 37 |\n",
    "| sex | m | f | m | f | m | f | m | f |\n",
    "| alpha | 0.19 | 0.98 | 0.03 | 0.36 | 0.37 | 0.20 | 0.11 | 0.31 |\n",
    "| beta | 9.86 | 5.74 | 3.15 | 6.53 | 3.07 | 3.21 | 7.53 | 1.80 |\n",
    "| w | 0.27 | 0.99 | 0.95 | 0.62 | 0.01 | 0.13 | 0.14 | 0.82 |\n",
    "| gamma | 0.02 | 0.12 | 0.00 | 0.02 | 0.03 | 0.04 | 0.01 | 0.50 |\n",
    "| reward | 161.00 | 161.00 | 147.00 | 134.00 | 144.00 | 128.00 | 145.00 | 153.00 |\n",
    "| catch correct | 3.00 | 5.00 | 5.00 | 4.00 | 4.00 | 4.00 | 5.00 | 0.00 |\n",
    "| valid trials | 297.00 | 298.00 | 297.00 | 298.00 | 298.00 | 299.00 | 300.00 | 292.00 |\n",
    "| AIC | 487.11 | 572.25 | 821.93 | 624.35 | 751.68 | 807.73 | 639.33 | 812.44 |\n",
    "| BIC | 33.77 | 34.10 | 34.83 | 34.28 | 34.65 | 34.80 | 34.32 | 34.81 |\n",
    "| mean p(S1) | 0.63 | 0.64 | 0.50 | 0.56 | 0.57 | 0.51 | 0.54 | 0.50 |\n",
    "| pval | 0.00 | 0.00 | 0.73 | 0.00 | 0.00 | 0.05 | 0.00 | 0.01 |\n",
    "| t-stat | 10.81 | 11.64 | 0.35 | 6.66 | 9.32 | 1.99 | 4.52 | 2.48 |\n",
    "| mean p(S2) | 0.85 | 0.72 | 0.52 | 0.74 | 0.56 | 0.54 | 0.75 | 0.50 |\n",
    "| pval | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.19 |\n",
    "| t-stat | 26.81 | 15.15 | 3.36 | 16.12 | 5.37 | 5.21 | 18.12 | 1.30 |\n",
    "\n",
    "* Model 3: model with $\\alpha$, $\\beta$, and $w$ (without decay)\n",
    "\n",
    "|  | sub1 | sub2 | sub3 | sub4 | sub5 | sub6 | sub7 | sub8 |\n",
    "|-|-|-|-|-|-|-|-|-|\n",
    "| age | 38 | 22 | 27 | 48 | 34 | 66 | 29 | 37 |\n",
    "| sex | m | f | m | f | m | f | m | f |\n",
    "| alpha | 0.06 | 0.91 | 0.04 | 0.39 | 0.11 | 0.27 | 0.13 | 0.96 |\n",
    "| beta | 7.26 | 3.51 | 2.81 | 5.39 | 3.81 | 1.75 | 5.69 | 0.31 |\n",
    "| w | 0.23 | 1.00 | 0.95 | 0.84 | 0.01 | 0.57 | 0.43 | 0.46 |\n",
    "| reward | 161.00 | 161.00 | 147.00 | 134.00 | 144.00 | 128.00 | 145.00 | 153.00 |\n",
    "| catch correct | 3.00 | 5.00 | 5.00 | 4.00 | 4.00 | 4.00 | 5.00 | 0.00 |\n",
    "| valid trials | 297.00 | 298.00 | 297.00 | 298.00 | 298.00 | 299.00 | 300.00 | 292.00 |\n",
    "| AIC | 547.52 | 602.70 | 818.79 | 646.84 | 761.43 | 816.49 | 654.95 | 812.50 |\n",
    "| BIC | 28.31 | 28.51 | 29.13 | 28.65 | 28.98 | 29.12 | 28.68 | 29.11 |\n",
    "| mean p(S1) | 0.58 | 0.60 | 0.50 | 0.54 | 0.57 | 0.50 | 0.54 | 0.50 |\n",
    "| pval | 0.00 | 0.00 | 0.63 | 0.00 | 0.00 | 0.73 | 0.00 | 0.10 |\n",
    "| t-stat | 7.93 | 9.98 | 0.48 | 5.01 | 9.36 | 0.35 | 4.92 | 1.66 |\n",
    "| mean p(S2) | 0.83 | 0.73 | 0.52 | 0.72 | 0.54 | 0.53 | 0.72 | 0.50 |\n",
    "| pval | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.18 |\n",
    "| t-stat | 23.66 | 15.08 | 3.35 | 15.26 | 3.81 | 4.67 | 15.83 | 1.33 |\n",
    "\n",
    "* Notes: \n",
    "1. Parameter recovery of model 3 is good (alpha = 0.87, beta = 0.91, w = 0.82), so reliable\n",
    "2. Model 3 outperforms model 1 in BIC: should focus on model 3 for the following analyses?\n",
    "3. $w$ are higher for model 3 \n",
    "4. It is highly likely that the 3th, 6th, and 8th subject made random choices, based on: 1) low $\\beta$, 2) high AIC/BIC scores, and  3) subjective values of selected options not significantly higher than 0.5 in stage 1. Also, sub 8 did not get any catch trials correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [-0.74  0.    0.04 -0.02 -0.01]\n",
    "# [-0.14 -0.   -0.   -0.07  0.  ]\n",
    "# [-0.13 -0.   -0.01  0.05 -0.02]\n",
    "# [ 0.15  0.    0.01 -0.02 -0.01]\n",
    "# [ 0.44  0.    0.02 -0.04 -0.  ]\n",
    "# [-0.08  0.    0.01  0.01 -0.01]\n",
    "# [ 0.23 -0.   -0.04 -0.05  0.02]\n",
    "# [-0.06 -0.   -0.08  0.01 -0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, sub in enumerate(subList):\n",
    "\n",
    "    df = pd.DataFrame(pd.read_csv(sub))\n",
    "\n",
    "\n",
    "    score = np.asarray(df['score'].iloc[-nTotal:])\n",
    "    title = 'Learning curve of subject ' + str(i+1)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Number of trials')\n",
    "    plt.ylabel('Score')\n",
    "    plt.plot(range(nTotal),score)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Do 1st-stage RTs correlate with subjective value difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2) Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # for i, sub in enumerate(subList):\n",
    "# for i in range(197):\n",
    "# #     rt1, rt2, Qvals_stage1, Qvals_stage2, Qmb_stage1, Qmf_stage1, prevWin, prevChoice1, stim_s1_left, choice1, trialnum = get_data(i)\n",
    "\n",
    "# #     df = pd.DataFrame(pd.read_csv(sub))\n",
    "# #     rt1 = df['rt_1'].iloc[-nTotal:]\n",
    "# #     rt2 = df['rt_2'].iloc[-nTotal:]\n",
    "#     data_filename = 'model1_trialdata_data_sub' + str(i+1) + '.txt'\n",
    "#     value_filename = 'model1_trialdata_value_sub' + str(i+1) + '.txt'\n",
    "#     data_filepath = os.path.join('./trialdata', data_filename)\n",
    "#     value_filepath = os.path.join('./trialdata', value_filename)\n",
    "# #     file = filepath.replace('.csv', '.mat.txt')\n",
    "\n",
    "# #     trial_data = pd.read_csv(file, header=None)\n",
    "    \n",
    "#     trial_data = pd.read_csv(value_filepath, header=None)\n",
    "#     other_data = pd.read_csv(data_filepath, header=None)\n",
    "    \n",
    "#     trialnum = other_data.iloc[:,0]\n",
    "#     prevWin = other_data.iloc[:,1]\n",
    "#     isLeft = other_data.iloc[:,2]\n",
    "#     rt1 = other_data.iloc[:,3]\n",
    "#     rt2 = other_data.iloc[:,4]\n",
    "    \n",
    "#     val_diff = np.abs(trial_data.iloc[:,2] - trial_data.iloc[:,3])\n",
    "    \n",
    "# #     print(Qvals_stage1)\n",
    "# #     val_diff= np.abs(Qvals_stage1[:,0] - Qvals_stage1[:,1])\n",
    "# #     val_diff = np.abs(trial_data.iloc[:,0] - trial_data.iloc[:,1])\n",
    "    \n",
    "# #     val_diff[val_diff==0] = 0.00001\n",
    "    \n",
    "    \n",
    "#     x = val_diff\n",
    "#     y = np.log(rt1[rt2!=-1])\n",
    "    \n",
    "#     slope, intercept = np.polyfit(x,y,1) # linear model adjustmen    \n",
    "    \n",
    "#     # to plot the adjusted model\n",
    "#     x_line = np.linspace(np.min(x), np.max(x), 100)\n",
    "#     y_line = np.polyval([slope, intercept], x_line)    \n",
    "#     plt.plot(x_line, y_line, color = 'red')\n",
    "#     correlation_coef = np.corrcoef(x,y)[0,1]\n",
    "#     plt.annotate('r = '+str(np.round(correlation_coef,2)),\n",
    "#         xy=(1,0),xycoords='axes fraction',\n",
    "#         xytext=(-20, 20), textcoords='offset pixels',\n",
    "#         horizontalalignment='right',\n",
    "#         verticalalignment='bottom')     \n",
    "#     title = 'Subject ' + str(i+1)\n",
    "#     plt.title(title)\n",
    "#     plt.xlabel('Subjective value difference')\n",
    "#     plt.ylabel('log RT')\n",
    "        \n",
    "#     plt.scatter(x,y)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Do 2nd-stage RTs correlate with subjective value difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2) Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# malsubjects = [12, 27, 34, 38, 76, 104]\n",
    "malsubjects = [16, 40, 64, 96, 140, 143, 154]\n",
    "valid_subind = pd.read_csv('valid_subind.txt')\n",
    "validind = np.array(valid_subind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(197):\n",
    "# #     rt1, rt2, Qvals_stage1, Qvals_stage2, Qmb_stage1, Qmf_stage1, prevWin, prevChoice1, stim_s1_left, choice1, trialnum = get_data(i)\n",
    "\n",
    "# #     df = pd.DataFrame(pd.read_csv(sub))\n",
    "# #     rt1 = df['rt_1'].iloc[-nTotal:]\n",
    "# #     rt2 = df['rt_2'].iloc[-nTotal:]\n",
    "#     data_filename = 'model1_trialdata_data_sub' + str(i+1) + '.txt'\n",
    "#     value_filename = 'model1_trialdata_value_sub' + str(i+1) + '.txt'\n",
    "#     data_filepath = os.path.join('./trialdata', data_filename)\n",
    "#     value_filepath = os.path.join('./trialdata', value_filename)\n",
    "# #     file = filepath.replace('.csv', '.mat.txt')\n",
    "\n",
    "# #     trial_data = pd.read_csv(file, header=None)\n",
    "    \n",
    "#     trial_data = pd.read_csv(value_filepath, header=None)\n",
    "#     other_data = pd.read_csv(data_filepath, header=None)\n",
    "    \n",
    "#     trialnum = other_data.iloc[:,0]\n",
    "#     prevWin = other_data.iloc[:,1]\n",
    "#     isLeft = other_data.iloc[:,2]\n",
    "#     rt1 = other_data.iloc[:,3]\n",
    "#     rt2 = other_data.iloc[:,4]\n",
    "#     val_diff = np.abs(trial_data.iloc[:,2] - trial_data.iloc[:,3])\n",
    "\n",
    "#     val_diff[val_diff==0] = 0.00001\n",
    "\n",
    "\n",
    "#     x = val_diff\n",
    "#     y = np.log(rt2[rt2!=-1])\n",
    "\n",
    "#     slope, intercept = np.polyfit(x,y,1) # linear model adjustmen    \n",
    "\n",
    "#     # to plot the adjusted model\n",
    "#     x_line = np.linspace(np.min(x), np.max(x), 100)\n",
    "#     y_line = np.polyval([slope, intercept], x_line)    \n",
    "#     plt.plot(x_line, y_line, color = 'red')\n",
    "#     correlation_coef = np.corrcoef(x,y)[0,1]\n",
    "#     plt.annotate('r = '+str(np.round(correlation_coef,2)),\n",
    "#         xy=(1,0),xycoords='axes fraction',\n",
    "#         xytext=(-20, 20), textcoords='offset pixels',\n",
    "#         horizontalalignment='right',\n",
    "#         verticalalignment='bottom')     \n",
    "#     title = 'Subject ' + str(i+1)\n",
    "#     plt.title(title)\n",
    "#     plt.xlabel('Subjective value difference')\n",
    "#     plt.ylabel('log RT')\n",
    "\n",
    "#     plt.scatter(x,y)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Regression: MB+MF as subjective value (w * MB + (1-w) * MF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2) Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04845433174674473\n",
      "0.08257383448174782\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# malsubjects += 1\n",
    "coef_x1 = []\n",
    "R2 = []\n",
    "for i in range(197):\n",
    "    if (i+1 in validind) and (i not in malsubjects):\n",
    "    #     rt1, rt2, Qvals_stage1, Qvals_stage2, Qmb_stage1, Qmf_stage1, prevWin, prevChoice1, stim_s1_left, choice1, trialnum = get_data(i)\n",
    "\n",
    "    #     df = pd.DataFrame(pd.read_csv(sub))\n",
    "    #     rt1 = df['rt_1'].iloc[-nTotal:]\n",
    "    #     rt2 = df['rt_2'].iloc[-nTotal:]\n",
    "        data_filename = 'model1_trialdata_data_sub' + str(i+1) + '.txt'\n",
    "        value_filename = 'model1_trialdata_value_sub' + str(i+1) + '.txt'\n",
    "        data_filepath = os.path.join('./trialdata', data_filename)\n",
    "        value_filepath = os.path.join('./trialdata', value_filename)\n",
    "    #     file = filepath.replace('.csv', '.mat.txt')\n",
    "\n",
    "    #     trial_data = pd.read_csv(file, header=None)\n",
    "\n",
    "        trial_data = pd.read_csv(value_filepath, header=None)\n",
    "        other_data = pd.read_csv(data_filepath, header=None)\n",
    "\n",
    "        trialnum = other_data.iloc[:,0]\n",
    "        prevWin = other_data.iloc[:,1]\n",
    "        isLeft = other_data.iloc[:,2]\n",
    "        rt1 = other_data.iloc[:,3]\n",
    "        rt2 = other_data.iloc[:,4]\n",
    "\n",
    "        x2 = trialnum # regressor 2: trial number \n",
    "        x3 = prevWin # regressor 3: if previous outcome was rewarded or no-reward\n",
    "        x4 = isLeft\n",
    "\n",
    "\n",
    "        val_diff = np.abs(trial_data.iloc[:,0] - trial_data.iloc[:,1])\n",
    "    #     val_diff = trial_data.iloc[:,0] - trial_data.iloc[:,1]\n",
    "\n",
    "        x1 = np.array(val_diff) # regressor of interest: absolute subjective value-difference\n",
    "    #     x3_= np.array(r[rt2!=-1])\n",
    "\n",
    "    #     x4 = np.array(isLeft[rt2!=-1].astype(int)) # regressor 4: which button used (just Left)\n",
    "    #     x5 = np.zeros(len(val_diff)) # regressor 5: experience of each rocket pair\n",
    "    #     x6 = np.zeros(len(val_diff)) # regressor 6: experience of each chosen rocket\n",
    "\n",
    "    #     for j in range(len(val_diff)):\n",
    "    #         x5[j] = np.count_nonzero(current_state_index[:j] == current_state_index[j])\n",
    "    #         x6[j] = np.count_nonzero(choice1[:j] == choice1[j])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        x = np.c_[x1,x2,x3,x4]\n",
    "        y = np.array(np.log(rt1[rt2!=-1]))\n",
    "\n",
    "        mlr = LinearRegression()\n",
    "        mlr.fit(x, y)\n",
    "#         print(np.round(mlr.coef_,2), np.round(mlr.score(x,y),2))\n",
    "        coef_x1.append(mlr.coef_[0])\n",
    "        R2.append(mlr.score(x,y))\n",
    "print(np.mean(np.array(coef_x1)))\n",
    "print(np.mean(np.array(R2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Model 3: signed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.014287434195581261\n",
      "0.08127878601670314\n"
     ]
    }
   ],
   "source": [
    "# malsubjects += 1\n",
    "coef_x1 = []\n",
    "R2 = []\n",
    "for i in range(197):\n",
    "    if (i+1 in validind) and (i not in malsubjects):\n",
    "    #     rt1, rt2, Qvals_stage1, Qvals_stage2, Qmb_stage1, Qmf_stage1, prevWin, prevChoice1, stim_s1_left, choice1, trialnum = get_data(i)\n",
    "\n",
    "    #     df = pd.DataFrame(pd.read_csv(sub))\n",
    "    #     rt1 = df['rt_1'].iloc[-nTotal:]\n",
    "    #     rt2 = df['rt_2'].iloc[-nTotal:]\n",
    "        data_filename = 'model1_trialdata_data_sub' + str(i+1) + '.txt'\n",
    "        value_filename = 'model1_trialdata_value_sub' + str(i+1) + '.txt'\n",
    "        data_filepath = os.path.join('./trialdata', data_filename)\n",
    "        value_filepath = os.path.join('./trialdata', value_filename)\n",
    "    #     file = filepath.replace('.csv', '.mat.txt')\n",
    "\n",
    "    #     trial_data = pd.read_csv(file, header=None)\n",
    "\n",
    "        trial_data = pd.read_csv(value_filepath, header=None)\n",
    "        other_data = pd.read_csv(data_filepath, header=None)\n",
    "\n",
    "        trialnum = other_data.iloc[:,0]\n",
    "        prevWin = other_data.iloc[:,1]\n",
    "        isLeft = other_data.iloc[:,2]\n",
    "        rt1 = other_data.iloc[:,3]\n",
    "        rt2 = other_data.iloc[:,4]\n",
    "\n",
    "        x2 = trialnum # regressor 2: trial number \n",
    "        x3 = prevWin # regressor 3: if previous outcome was rewarded or no-reward\n",
    "        x4 = isLeft\n",
    "\n",
    "\n",
    "        val_diff = trial_data.iloc[:,0] - trial_data.iloc[:,1]\n",
    "    #     val_diff = trial_data.iloc[:,0] - trial_data.iloc[:,1]\n",
    "\n",
    "        x1 = np.array(val_diff) # regressor of interest: absolute subjective value-difference\n",
    "    #     x3_= np.array(r[rt2!=-1])\n",
    "\n",
    "    #     x4 = np.array(isLeft[rt2!=-1].astype(int)) # regressor 4: which button used (just Left)\n",
    "    #     x5 = np.zeros(len(val_diff)) # regressor 5: experience of each rocket pair\n",
    "    #     x6 = np.zeros(len(val_diff)) # regressor 6: experience of each chosen rocket\n",
    "\n",
    "    #     for j in range(len(val_diff)):\n",
    "    #         x5[j] = np.count_nonzero(current_state_index[:j] == current_state_index[j])\n",
    "    #         x6[j] = np.count_nonzero(choice1[:j] == choice1[j])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        x = np.c_[x1,x2,x3,x4]\n",
    "        y = np.array(np.log(rt1[rt2!=-1]))\n",
    "\n",
    "        mlr = LinearRegression()\n",
    "        mlr.fit(x, y)\n",
    "#         print(np.round(mlr.coef_,2), np.round(mlr.score(x,y),2))\n",
    "        coef_x1.append(mlr.coef_[0])\n",
    "        R2.append(mlr.score(x,y))\n",
    "print(np.mean(np.array(coef_x1)))\n",
    "print(np.mean(np.array(R2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-5) Model 3 - 2nd stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:726: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-8d049753ff55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mmlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mmlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;31m#         print(np.round(mlr.coef_,2), np.round(mlr.score(x,y),2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mcoef_x1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0m\u001b[1;32m    506\u001b[0m                                    y_numeric=True, multi_output=True)\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    802\u001b[0m                     estimator=estimator)\n\u001b[1;32m    803\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n\u001b[0m\u001b[1;32m    805\u001b[0m                         ensure_2d=False, dtype=None)\n\u001b[1;32m    806\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# malsubjects += 1\n",
    "coef_x1 = []\n",
    "R2 = []\n",
    "for i in range(197):\n",
    "    if (i+1 in validind) and (i not in malsubjects):\n",
    "    #     rt1, rt2, Qvals_stage1, Qvals_stage2, Qmb_stage1, Qmf_stage1, prevWin, prevChoice1, stim_s1_left, choice1, trialnum = get_data(i)\n",
    "\n",
    "    #     df = pd.DataFrame(pd.read_csv(sub))\n",
    "    #     rt1 = df['rt_1'].iloc[-nTotal:]\n",
    "    #     rt2 = df['rt_2'].iloc[-nTotal:]\n",
    "        data_filename = 'model1_trialdata_data_sub' + str(i+1) + '.txt'\n",
    "        value_filename = 'model1_trialdata_value_sub' + str(i+1) + '.txt'\n",
    "        data_filepath = os.path.join('./trialdata', data_filename)\n",
    "        value_filepath = os.path.join('./trialdata', value_filename)\n",
    "    #     file = filepath.replace('.csv', '.mat.txt')\n",
    "\n",
    "    #     trial_data = pd.read_csv(file, header=None)\n",
    "\n",
    "        trial_data = pd.read_csv(value_filepath, header=None)\n",
    "        other_data = pd.read_csv(data_filepath, header=None)\n",
    "\n",
    "        trialnum = other_data.iloc[:,0]\n",
    "        prevWin = other_data.iloc[:,1]\n",
    "        isLeft = other_data.iloc[:,2]\n",
    "        rt1 = other_data.iloc[:,3]\n",
    "        rt2 = other_data.iloc[:,4]\n",
    "\n",
    "        x2 = trialnum # regressor 2: trial number \n",
    "        x3 = prevWin # regressor 3: if previous outcome was rewarded or no-reward\n",
    "        x4 = isLeft\n",
    "\n",
    "\n",
    "        val_diff = np.abs(trial_data.iloc[:,2] - trial_data.iloc[:,3])\n",
    "    #     val_diff = trial_data.iloc[:,0] - trial_data.iloc[:,1]\n",
    "\n",
    "        x1 = np.array(val_diff) # regressor of interest: absolute subjective value-difference\n",
    "    #     x3_= np.array(r[rt2!=-1])\n",
    "\n",
    "    #     x4 = np.array(isLeft[rt2!=-1].astype(int)) # regressor 4: which button used (just Left)\n",
    "    #     x5 = np.zeros(len(val_diff)) # regressor 5: experience of each rocket pair\n",
    "    #     x6 = np.zeros(len(val_diff)) # regressor 6: experience of each chosen rocket\n",
    "\n",
    "    #     for j in range(len(val_diff)):\n",
    "    #         x5[j] = np.count_nonzero(current_state_index[:j] == current_state_index[j])\n",
    "    #         x6[j] = np.count_nonzero(choice1[:j] == choice1[j])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        x = np.c_[x1,x2,x3,x4]\n",
    "        y = np.array(np.log(rt2[rt2!=-1]))\n",
    "\n",
    "        mlr = LinearRegression()\n",
    "        mlr.fit(x, y)\n",
    "#         print(np.round(mlr.coef_,2), np.round(mlr.score(x,y),2))\n",
    "        coef_x1.append(mlr.coef_[0])\n",
    "        R2.append(mlr.score(x,y))\n",
    "print(np.mean(np.array(coef_x1)))\n",
    "print(np.mean(np.array(R2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Regression: just MB as subjective value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2) Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016329916565145843\n",
      "0.08113695103138277\n"
     ]
    }
   ],
   "source": [
    "MB_coef_x1 = []\n",
    "MB_R2 = []\n",
    "\n",
    "for i in range(197):\n",
    "    if (i+1 in validind) and (i not in malsubjects):\n",
    "\n",
    "        data_filename = 'model1_trialdata_data_sub' + str(i+1) + '.txt'\n",
    "        value_filename = 'model1_trialdata_value_sub' + str(i+1) + '.txt'\n",
    "        data_filepath = os.path.join('./trialdata', data_filename)\n",
    "        value_filepath = os.path.join('./trialdata', value_filename)\n",
    "\n",
    "        trial_data = pd.read_csv(value_filepath, header=None)\n",
    "        other_data = pd.read_csv(data_filepath, header=None)\n",
    "\n",
    "        trialnum = other_data.iloc[:,0]\n",
    "        prevWin = other_data.iloc[:,1]\n",
    "        isLeft = other_data.iloc[:,2]\n",
    "        \n",
    "        prevWin[0] = 0\n",
    "        \n",
    "        rt1 = other_data.iloc[:,3]\n",
    "        rt2 = other_data.iloc[:,4]\n",
    "\n",
    "        x2 = trialnum # regressor 2: trial number \n",
    "        x3 = prevWin # regressor 3: if previous outcome was rewarded or no-reward\n",
    "        x4 = isLeft\n",
    "        val_diff = np.abs(trial_data.iloc[:,4] - trial_data.iloc[:,5])\n",
    "    #     val_diff = trial_data.iloc[:,8] - trial_data.iloc[:,9]\n",
    "\n",
    "        x1 = np.array(val_diff) # regressor of interest: absolute subjective value-difference\n",
    "        x = np.c_[x1,x2,x3,x4]\n",
    "#         y = np.array(rt1[rt2!=-1])\n",
    "        y = np.array(np.log(rt1))\n",
    "\n",
    "        mlr = LinearRegression()\n",
    "        mlr.fit(x, y)\n",
    "#         print(np.round(mlr.coef_,2), np.round(mlr.score(x,y),2))\n",
    "        MB_coef_x1.append(mlr.coef_[0])\n",
    "        MB_R2.append(mlr.score(x,y))\n",
    "        \n",
    "#         if np.abs(mlr.coef_[0]) > 100:\n",
    "#             print('Subject {} is suspicious'.format(i))\n",
    "#             print(x1)\n",
    "print(np.mean(np.array(MB_coef_x1)))\n",
    "print(np.mean(np.array(MB_R2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-3) Model 3: Signed subjective value difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05975991000733802\n",
      "0.08044501248465963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.7445e-09]),\n",
       " array([1.]),\n",
       " array([0.63071]),\n",
       " array([0.62425]),\n",
       " array([1.]),\n",
       " array([2.7582e-08]),\n",
       " array([0.51009]),\n",
       " array([1.1095e-07]),\n",
       " array([1.]),\n",
       " array([1.2607e-08]),\n",
       " array([0.68838]),\n",
       " array([2.6245e-09]),\n",
       " array([0.51906]),\n",
       " array([3.0716e-09]),\n",
       " array([0.34469]),\n",
       " array([8.395e-09]),\n",
       " array([0.3746]),\n",
       " array([0.36426]),\n",
       " array([2.9652e-09]),\n",
       " array([1.3557e-07]),\n",
       " array([3.0774e-09]),\n",
       " array([0.79673]),\n",
       " array([0.00091324]),\n",
       " array([0.44467]),\n",
       " array([0.11099]),\n",
       " array([0.57623]),\n",
       " array([3.1046e-08]),\n",
       " array([0.92376]),\n",
       " array([2.7522e-09]),\n",
       " array([3.9616e-09]),\n",
       " array([1.6844e-09]),\n",
       " array([1.7141e-08]),\n",
       " array([0.13174]),\n",
       " array([4.915e-09]),\n",
       " array([0.7232]),\n",
       " array([1.0908e-07]),\n",
       " array([0.5897]),\n",
       " array([0.56643]),\n",
       " array([0.78187]),\n",
       " array([5.1358e-08]),\n",
       " array([0.61798]),\n",
       " array([0.90983]),\n",
       " array([1.4131e-08]),\n",
       " array([5.1581e-09]),\n",
       " array([7.2184e-09]),\n",
       " array([4.7049e-09]),\n",
       " array([0.77379]),\n",
       " array([0.13421]),\n",
       " array([0.62908]),\n",
       " array([0.33224]),\n",
       " array([0.37645]),\n",
       " array([0.12976]),\n",
       " array([0.9939]),\n",
       " array([4.8922e-09]),\n",
       " array([1.7611e-08]),\n",
       " array([0.12642]),\n",
       " array([0.90969]),\n",
       " array([0.092839]),\n",
       " array([1.5948e-07]),\n",
       " array([0.083955]),\n",
       " array([2.0133e-09]),\n",
       " array([0.18239]),\n",
       " array([0.9061]),\n",
       " array([6.0692e-09]),\n",
       " array([4.9329e-09]),\n",
       " array([5.7762e-09]),\n",
       " array([0.26728]),\n",
       " array([1.]),\n",
       " array([0.68609]),\n",
       " array([0.77323]),\n",
       " array([2.8207e-09]),\n",
       " array([0.13627]),\n",
       " array([0.34728]),\n",
       " array([7.1758e-09]),\n",
       " array([0.66528]),\n",
       " array([0.78127]),\n",
       " array([2.0642e-08]),\n",
       " array([3.6064e-09]),\n",
       " array([0.77918]),\n",
       " array([0.23502]),\n",
       " array([0.9053]),\n",
       " array([2.6819e-09]),\n",
       " array([2.4062e-08]),\n",
       " array([3.7601e-07]),\n",
       " array([3.1262e-09]),\n",
       " array([0.22474]),\n",
       " array([0.47321]),\n",
       " array([0.83084]),\n",
       " array([0.79808]),\n",
       " array([0.66428]),\n",
       " array([0.09151]),\n",
       " array([1.]),\n",
       " array([0.36505]),\n",
       " array([0.73053]),\n",
       " array([1.1992e-09]),\n",
       " array([2.6919e-09]),\n",
       " array([0.27608]),\n",
       " array([0.4661]),\n",
       " array([1.2669e-09]),\n",
       " array([1.6082e-09]),\n",
       " array([1.8136e-09]),\n",
       " array([1.0424e-09]),\n",
       " array([0.69845]),\n",
       " array([1.4015e-08]),\n",
       " array([0.11065]),\n",
       " array([0.5531]),\n",
       " array([0.59642]),\n",
       " array([3.0993e-08]),\n",
       " array([5.5426e-09]),\n",
       " array([0.81355]),\n",
       " array([2.9617e-09]),\n",
       " array([2.2437e-09]),\n",
       " array([6.9338e-09]),\n",
       " array([6.4094e-08]),\n",
       " array([0.58004]),\n",
       " array([0.49558]),\n",
       " array([0.76391]),\n",
       " array([0.45297]),\n",
       " array([3.8911e-08]),\n",
       " array([1.]),\n",
       " array([0.43279]),\n",
       " array([4.857e-08]),\n",
       " array([1.7372e-08]),\n",
       " array([2.7984e-09]),\n",
       " array([0.74396]),\n",
       " array([3.218e-09]),\n",
       " array([0.29456]),\n",
       " array([0.68155]),\n",
       " array([2.6145e-09]),\n",
       " array([7.4252e-08]),\n",
       " array([0.1085]),\n",
       " array([8.4206e-09]),\n",
       " array([5.6202e-08]),\n",
       " array([6.3967e-09]),\n",
       " array([0.1477]),\n",
       " array([2.5092e-09]),\n",
       " array([3.0281e-08]),\n",
       " array([1.4561e-06]),\n",
       " array([0.20611])]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MB_coef_x1_sign = []\n",
    "MB_R2_sign = []\n",
    "w0=[]\n",
    "w_file = 'w.txt'\n",
    "w = pd.read_csv(w_file,header=None)\n",
    "w = np.asarray(w)\n",
    "for i in range(197):\n",
    "    if (i+1 in validind) and (i not in malsubjects):\n",
    "\n",
    "        data_filename = 'model1_trialdata_data_sub' + str(i+1) + '.txt'\n",
    "        value_filename = 'model1_trialdata_value_sub' + str(i+1) + '.txt'\n",
    "        \n",
    "        data_filepath = os.path.join('./trialdata', data_filename)\n",
    "        value_filepath = os.path.join('./trialdata', value_filename)\n",
    "#         w_filepath = \n",
    "        trial_data = pd.read_csv(value_filepath, header=None)\n",
    "        other_data = pd.read_csv(data_filepath, header=None)\n",
    "        \n",
    "        w0.append(w[i])\n",
    "        trialnum = other_data.iloc[:,0]\n",
    "        prevWin = other_data.iloc[:,1]\n",
    "        isLeft = other_data.iloc[:,2]\n",
    "        \n",
    "        prevWin[0] = 0\n",
    "        \n",
    "        rt1 = other_data.iloc[:,3]\n",
    "        rt2 = other_data.iloc[:,4]\n",
    "\n",
    "        x2 = trialnum # regressor 2: trial number \n",
    "        x3 = prevWin # regressor 3: if previous outcome was rewarded or no-reward\n",
    "        x4 = isLeft\n",
    "        val_diff = trial_data.iloc[:,4] - trial_data.iloc[:,5]\n",
    "\n",
    "        x1 = np.array(val_diff) # regressor of interest: absolute subjective value-difference\n",
    "        x = np.c_[x1,x2,x3,x4]\n",
    "#         y = np.array(rt1[rt2!=-1])\n",
    "        y = np.array(np.log(rt1))\n",
    "\n",
    "        mlr = LinearRegression()\n",
    "        mlr.fit(x, y)\n",
    "#         print(np.round(mlr.coef_,2), np.round(mlr.score(x,y),2))\n",
    "        MB_coef_x1_sign.append(mlr.coef_[0])\n",
    "        MB_R2_sign.append(mlr.score(x,y))\n",
    "        \n",
    "#         if np.abs(mlr.coef_[0]) > 100:\n",
    "#             print('Subject {} is suspicious'.format(i))\n",
    "#             print(x1)\n",
    "print(np.mean(np.array(MB_coef_x1_sign)))\n",
    "print(np.mean(np.array(MB_R2_sign)))\n",
    "\n",
    "w0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Regression: just MF as subjective value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-2) Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.041077949241828414\n",
      "0.08149089936022527\n"
     ]
    }
   ],
   "source": [
    "MF_coef_x1 = []\n",
    "MF_R2 = []\n",
    "\n",
    "for i in range(197):\n",
    "    if (i+1 in validind) and (i not in malsubjects):\n",
    "\n",
    "        data_filename = 'model1_trialdata_data_sub' + str(i+1) + '.txt'\n",
    "        value_filename = 'model1_trialdata_value_sub' + str(i+1) + '.txt'\n",
    "        data_filepath = os.path.join('./trialdata', data_filename)\n",
    "        value_filepath = os.path.join('./trialdata', value_filename)\n",
    "\n",
    "        trial_data = pd.read_csv(value_filepath, header=None)\n",
    "        other_data = pd.read_csv(data_filepath, header=None)\n",
    "\n",
    "        trialnum = other_data.iloc[:,0]\n",
    "        prevWin = other_data.iloc[:,1]\n",
    "        isLeft = other_data.iloc[:,2]\n",
    "        \n",
    "        prevWin[0] = 0\n",
    "        \n",
    "        rt1 = other_data.iloc[:,3]\n",
    "        rt2 = other_data.iloc[:,4]\n",
    "\n",
    "        x2 = trialnum # regressor 2: trial number \n",
    "        x3 = prevWin # regressor 3: if previous outcome was rewarded or no-reward\n",
    "        x4 = isLeft\n",
    "        val_diff = np.abs(trial_data.iloc[:,6] - trial_data.iloc[:,7])\n",
    "    #     val_diff = trial_data.iloc[:,8] - trial_data.iloc[:,9]\n",
    "\n",
    "        x1 = np.array(val_diff) # regressor of interest: absolute subjective value-difference\n",
    "        x = np.c_[x1,x2,x3,x4]\n",
    "#         y = np.array(rt1[rt2!=-1])\n",
    "        y = np.array(np.log(rt1))\n",
    "\n",
    "        mlr = LinearRegression()\n",
    "        mlr.fit(x, y)\n",
    "#         print(np.round(mlr.coef_,2), np.round(mlr.score(x,y),2))\n",
    "        MF_coef_x1.append(mlr.coef_[0])\n",
    "        MF_R2.append(mlr.score(x,y))\n",
    "        \n",
    "#         if np.abs(mlr.coef_[0]) > 100:\n",
    "#             print('Subject {} is suspicious'.format(i))\n",
    "#             print(x1)\n",
    "print(np.mean(np.array(MF_coef_x1)))\n",
    "print(np.mean(np.array(MF_R2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-3) Signed subjective value difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.022127883950419428\n",
      "0.08112484486898083\n"
     ]
    }
   ],
   "source": [
    "MF_coef_x1_sign = []\n",
    "MF_R2_sign = []\n",
    "\n",
    "for i in range(197):\n",
    "    if (i+1 in validind) and (i not in malsubjects):\n",
    "\n",
    "        data_filename = 'model1_trialdata_data_sub' + str(i+1) + '.txt'\n",
    "        value_filename = 'model1_trialdata_value_sub' + str(i+1) + '.txt'\n",
    "        data_filepath = os.path.join('./trialdata', data_filename)\n",
    "        value_filepath = os.path.join('./trialdata', value_filename)\n",
    "\n",
    "        trial_data = pd.read_csv(value_filepath, header=None)\n",
    "        other_data = pd.read_csv(data_filepath, header=None)\n",
    "\n",
    "        trialnum = other_data.iloc[:,0]\n",
    "        prevWin = other_data.iloc[:,1]\n",
    "        isLeft = other_data.iloc[:,2]\n",
    "        \n",
    "        prevWin[0] = 0\n",
    "        \n",
    "        rt1 = other_data.iloc[:,3]\n",
    "        rt2 = other_data.iloc[:,4]\n",
    "\n",
    "        x2 = trialnum # regressor 2: trial number \n",
    "        x3 = prevWin # regressor 3: if previous outcome was rewarded or no-reward\n",
    "        x4 = isLeft\n",
    "        val_diff = trial_data.iloc[:,6] - trial_data.iloc[:,7]\n",
    "    #     val_diff = trial_data.iloc[:,8] - trial_data.iloc[:,9]\n",
    "\n",
    "        x1 = np.array(val_diff) # regressor of interest: absolute subjective value-difference\n",
    "        x = np.c_[x1,x2,x3,x4]\n",
    "#         y = np.array(rt1[rt2!=-1])\n",
    "        y = np.array(np.log(rt1))\n",
    "\n",
    "        mlr = LinearRegression()\n",
    "        mlr.fit(x, y)\n",
    "#         print(np.round(mlr.coef_,2), np.round(mlr.score(x,y),2))\n",
    "        MF_coef_x1_sign.append(mlr.coef_[0])\n",
    "        MF_R2_sign.append(mlr.score(x,y))\n",
    "        \n",
    "#         if np.abs(mlr.coef_[0]) > 100:\n",
    "#             print('Subject {} is suspicious'.format(i))\n",
    "#             print(x1)\n",
    "print(np.mean(np.array(MF_coef_x1_sign)))\n",
    "print(np.mean(np.array(MF_R2_sign)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.hstack((np.array(MB_coef_x1), np.array(MF_coef_x1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.95077412871601"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = np.array(MB_coef_x1)/np.array(MF_coef_x1)\n",
    "# ratio\n",
    "np.mean(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016329916565145843"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(MB_coef_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.041077949241828414"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(MF_coef_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,p = scipy.stats.ttest_ind(MB_coef_x1,MF_coef_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7210477881038444"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47149042286193166"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.95077412871601"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(MB_coef_x1)/np.array(MF_coef_x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   0.,   1.,   1.,  14., 100.,  16.,   5.,   1.]),\n",
       " array([-6.23845739, -5.27254948, -4.30664156, -3.34073365, -2.37482574,\n",
       "        -1.40891782, -0.44300991,  0.522898  ,  1.48880591,  2.45471383,\n",
       "         3.42062174]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(MB_coef_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0.,  0.,  1.,  2., 28., 87., 14.,  3.,  3.]),\n",
       " array([-2.59438373, -2.19245529, -1.79052686, -1.38859843, -0.98666999,\n",
       "        -0.58474156, -0.18281313,  0.2191153 ,  0.62104374,  1.02297217,\n",
       "         1.4249006 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(MF_coef_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.71674820e+00,  7.52960573e-01,  1.44258400e-02,  4.68290576e-01,\n",
       "       -1.22958322e+01,  6.50756200e+00, -1.65622803e+00,  4.32488009e-01,\n",
       "       -6.66026677e+00,  4.73306395e-01, -1.51689454e+01,  3.42758602e+00,\n",
       "       -3.62639999e+00, -4.01666171e+00,  2.70408731e+00, -2.31725079e+00,\n",
       "        8.38721376e-01, -9.95423832e-01,  2.13465821e+00, -1.71427045e+00,\n",
       "        7.02880749e+00,  1.53104790e+00, -5.41355741e-01, -3.79265251e+00,\n",
       "        9.54132470e-01, -4.33784191e+00,  5.41553935e+00,  4.50012217e-01,\n",
       "       -7.55056924e+01,  5.70592713e-01,  2.53805269e+00,  4.98397059e-01,\n",
       "        1.31970756e+00, -6.82863758e+00,  3.30077532e+00, -1.08809365e+00,\n",
       "        9.73131780e-01,  1.65069409e+00, -2.49269819e+00,  1.74939200e+00,\n",
       "        4.88401965e+00,  3.67776117e+00, -2.00234910e-01,  4.14010978e-01,\n",
       "       -6.79273388e+00,  1.61222751e+00, -3.58923200e-01,  3.00764739e+01,\n",
       "        3.83898947e+01,  3.56204899e-01, -3.89004255e+00, -2.18379768e+00,\n",
       "        2.27775536e+01,  1.15004906e+01,  6.35257885e-01, -1.05973572e+00,\n",
       "       -1.81155905e+03,  5.88927862e-01,  5.03058515e+00, -7.07586257e-01,\n",
       "        8.30291798e-01, -3.85163975e+00,  1.10745464e+00,  3.20004333e-01,\n",
       "       -1.31931254e+00,  2.77156211e+00, -6.19349838e-02,  9.37570033e-01,\n",
       "        6.92699607e+00, -1.23817959e+00,  1.66241010e+00,  3.81267194e-02,\n",
       "       -8.12255864e-01, -2.22644292e-01, -3.00151846e-01,  5.35000719e+00,\n",
       "       -6.46222051e-01,  9.33494606e-02, -4.89552101e+00,  3.92376725e-01,\n",
       "        1.23793557e+01,  7.91540709e-01, -4.45291256e+01,  1.03761897e+00,\n",
       "        9.29129122e-01,  2.05752393e-01, -6.07402583e-02,  2.03268748e+00,\n",
       "        1.65139717e+01,  1.40037579e+00,  1.15921839e+00, -7.86455222e+01,\n",
       "       -1.07988058e+00, -1.39746489e+00,  1.61942145e+01,  6.23028762e-01,\n",
       "        2.61891749e+00,  2.02115141e-01, -3.01815990e-01, -7.12391833e-01,\n",
       "        4.81991880e-01, -8.23566327e-01,  2.57903390e-01,  6.74198418e-01,\n",
       "       -5.67034191e+00,  2.63730370e+01,  3.89695365e+00,  1.07221978e+01,\n",
       "        3.38208620e+01,  2.85740915e+00,  5.24166360e-01,  1.89064854e+00,\n",
       "        3.24883770e-01, -2.83664597e+00,  6.71019476e-01,  6.16513484e+00,\n",
       "       -3.55674945e-01,  3.23101558e+00,  1.89235426e+00,  1.61134475e+00,\n",
       "        9.23399164e-01, -4.75702595e+00, -3.57772777e-01,  1.20276773e+00,\n",
       "       -1.07724348e+01,  8.83628534e+00, -5.48554582e-01,  6.07871535e+00,\n",
       "        1.68673513e+00, -1.68474138e+01,  4.44815457e+00, -2.08952227e+00,\n",
       "        1.14228852e-01,  3.74932732e+01, -1.25895836e+01, -2.19864995e+01,\n",
       "       -6.80115519e+00,  1.75521339e+00,  7.30751069e-01])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 138.]),\n",
       " array([-1811.55905222, -1626.56415753, -1441.56926284, -1256.57436815,\n",
       "        -1071.57947346,  -886.58457877,  -701.58968408,  -516.59478939,\n",
       "         -331.5998947 ,  -146.60500001,    38.38989468]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fab08f7c8b0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(MB_coef_x1, MF_coef_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_coef_x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.]]),\n",
       " array([1.04240000e-09, 1.00000001e-01, 2.00000001e-01, 3.00000001e-01,\n",
       "        4.00000001e-01, 5.00000001e-01, 6.00000000e-01, 7.00000000e-01,\n",
       "        8.00000000e-01, 9.00000000e-01, 1.00000000e+00]),\n",
       " <a list of 139 BarContainer objects>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29552064983229503"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(w0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
